{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Antenna documentation Note This documentation is a work in progress! If you notice problems or sections not up to date, please open an issue here . For contributions, checkout this article.","title":"Antenna documentation"},{"location":"#antenna-documentation","text":"Note This documentation is a work in progress! If you notice problems or sections not up to date, please open an issue here . For contributions, checkout this article.","title":"Antenna documentation"},{"location":"sections/dev-guide/developer-guide/","text":"Getting started Antenna uses Docker & Docker Compose to run all services locally for development. 1) Install Docker for your host operating (Linux, macOS, Windows) 2) Add the following to your /etc/hosts file in order to see and process the demo source images. This makes the hostname minio and django alias for localhost so the same image URLs can be viewed in the host machine's web browser and be processed by the ML services. This can be skipped if you are using an external image storage service. 127.0.0.1 minio 127.0.0.1 django 2) The following commands will build all services, run them in the background, and then stream the logs. docker compose up -d docker compose logs -f django celeryworker ui # Ctrl+c to close the logs 3) Optionally, run additional ML processing services: processing_services defines ML backends which wrap detections in our FastAPI response schema. The example app demos how to add new pipelines, algorithms, and models. See the detailed instructions in processing_services/README.md . docker compose -f processing_services/example/docker-compose.yml up -d # Once running, in Antenna register a new processing service called: http://ml_backend_example:2000 4) Access the platform the following URLs: Primary web interface: http://localhost:4000 API browser: http://localhost:8000/api/v2/ Django admin: http://localhost:8000/admin/ OpenAPI / Swagger documentation: http://localhost:8000/api/v2/docs/ A default user will be created with the following credentials. Use these to log into the web UI or the Django admin. Email: antenna@insectai.org Password: localadmin 5) Stop all services with: $ docker compose down Development Install the pre-commit tool to run linting & formatting checks before each git commit. It's typical to install this tool using your system-wide python. pip install pre-commit # Install pre-commit system-wide pre-commit install # Install the hook for our project Frontend Dependencies Node.js Yarn Configuration By default this will try to connect to http://localhost:8000 for the backend API. Use the env var API_PROXY_TARGET to change this. You can create multiple .env files in the ui/ directory for different environments or configurations. For example, use yarn start --mode staging to load .env.staging and point the API_PROXY_TARGET to a remote backend. Installation Note: if you installed the ui using Docker first (as instructed in the quick-start) then your local node_modules/ directory will be owned by root. Change the permissions with: sudo chown -R ${UID}:${UID} ui/node_modules . The version of Node on your host machine must match that of the Docker container (which will be the case if you follow the nvm instructions below.) # Enter into the ui directory cd ui # Install Node Version Manager curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash # Install required Node.js version nvm install # Install Yarn dependencies yarn install # Start the frontend yarn start Visit http://localhost:3000/ Backend Dependencies Docker Docker Compose All backend packages are installed in the docker containers, however for faster auto-completion and intellisense, you can install them on the host machine: python -m venv venv source venv/bin/activate pip install -r requirements/local.txt Helpful Commands Run the docker compose stack in the background docker compose up -d Watch the logs of Django & the backend workers docker compose logs -f django celeryworker Watch the logs of all services: docker compose logs -f Create a super user account: docker compose run --rm django python manage.py createsuperuser Create a fresh demo project with synthetic data docker compose run --rm django python manage.py create_demo_project Run tests docker compose run --rm django python manage.py test Run tests with a specific pattern in the test name docker compose run --rm django python manage.py test -k pattern Run tests and drop into interactive shell on failure docker compose run --rm django python manage.py test -k pattern --failfast --pdb Speed up development of tests by reusing the db between test runs docker compose run --rm django python manage.py test --keepdb Run management scripts docker compose run django python manage.py --help Launch the Django shell: docker compose exec django python manage.py shell >>> from ami.main.models import SourceImage, Occurrence >>> SourceImage.objects.all(project__name='myproject') Install backend dependencies locally for IDE support (Intellisense, etc): python -m venv venv source venv/bin/activate pip install -r requirements/local.txt Generate OpenAPI schema docker compose run --rm django python manage.py spectacular --api-version 'api' --format openapi --file ami-openapi-schema.yaml Generate TypeScript types from OpenAPI schema docker run --rm -v ${PWD}:/local openapitools/openapi-generator-cli generate -i /local/ami-openapi-schema.yaml -g typescript-axios -o /local/ui/src/api-schema.d.ts Generate diagram graph of Django models & relationships (Graphviz required) docker compose run --rm django python manage.py graph_models -a -o models.dot --dot dot -Tsvg models.dot > models.svg Project Data Storage Each project manages its own external data storage where the AMI Platform will index and process images. This is most typically a public or private S3 bucket at a cloud provider that is not AWS. For example, the Swift object storage service at Compute Canada or a university's own storage service. To test the S3 storage backend locally, Minio is configured to run as part of the docker compose stack. To configure a project connect to the Minio service, you can use the following config: Endpoint URL: http://minio:9000 Access key: amistorage Secret access key: amistorage Public base URL: http://minio:9000/ami/ Bucket: ami Open the Minio web interface at http://localhost:9001 and login with the access key and secret access key. Upload some test images to a subfolder in the ami bucket (one subfolder per deployment) Give the bucket or folder anonymous access using the \"Anonymous access\" button in the Minio web interface. Both public and private buckets with presigned URLs should work. Add entries to your local /etc/hosts file to map the minio and django hostnames to localhost so the same image URLs can be viewed in your host machine's browser and processed in the backend containers. 127.0.0.1 minio 127.0.0.1 django Email The local environment uses the console email backend. To view emails sent by the platform, check the console output (run the docker compose logs -f django celeryworker command). Database The local environment uses a local PostgreSQL database in a Docker container. Backup and Restore docker compose run --rm postgres backup Reset the database docker compose run --rm django python manage.py reset_db Show backups docker compose run --rm postgres backups Restore a backup docker compose run --rm postgres restore <backup_file_name> Load fixtures with test data docker compose run --rm django python manage.py migrate","title":"Getting started"},{"location":"sections/dev-guide/developer-guide/#getting-started","text":"Antenna uses Docker & Docker Compose to run all services locally for development. 1) Install Docker for your host operating (Linux, macOS, Windows) 2) Add the following to your /etc/hosts file in order to see and process the demo source images. This makes the hostname minio and django alias for localhost so the same image URLs can be viewed in the host machine's web browser and be processed by the ML services. This can be skipped if you are using an external image storage service. 127.0.0.1 minio 127.0.0.1 django 2) The following commands will build all services, run them in the background, and then stream the logs. docker compose up -d docker compose logs -f django celeryworker ui # Ctrl+c to close the logs 3) Optionally, run additional ML processing services: processing_services defines ML backends which wrap detections in our FastAPI response schema. The example app demos how to add new pipelines, algorithms, and models. See the detailed instructions in processing_services/README.md . docker compose -f processing_services/example/docker-compose.yml up -d # Once running, in Antenna register a new processing service called: http://ml_backend_example:2000 4) Access the platform the following URLs: Primary web interface: http://localhost:4000 API browser: http://localhost:8000/api/v2/ Django admin: http://localhost:8000/admin/ OpenAPI / Swagger documentation: http://localhost:8000/api/v2/docs/ A default user will be created with the following credentials. Use these to log into the web UI or the Django admin. Email: antenna@insectai.org Password: localadmin 5) Stop all services with: $ docker compose down","title":"Getting started"},{"location":"sections/dev-guide/developer-guide/#development","text":"Install the pre-commit tool to run linting & formatting checks before each git commit. It's typical to install this tool using your system-wide python. pip install pre-commit # Install pre-commit system-wide pre-commit install # Install the hook for our project","title":"Development"},{"location":"sections/dev-guide/developer-guide/#frontend","text":"","title":"Frontend"},{"location":"sections/dev-guide/developer-guide/#dependencies","text":"Node.js Yarn","title":"Dependencies"},{"location":"sections/dev-guide/developer-guide/#configuration","text":"By default this will try to connect to http://localhost:8000 for the backend API. Use the env var API_PROXY_TARGET to change this. You can create multiple .env files in the ui/ directory for different environments or configurations. For example, use yarn start --mode staging to load .env.staging and point the API_PROXY_TARGET to a remote backend.","title":"Configuration"},{"location":"sections/dev-guide/developer-guide/#installation","text":"Note: if you installed the ui using Docker first (as instructed in the quick-start) then your local node_modules/ directory will be owned by root. Change the permissions with: sudo chown -R ${UID}:${UID} ui/node_modules . The version of Node on your host machine must match that of the Docker container (which will be the case if you follow the nvm instructions below.) # Enter into the ui directory cd ui # Install Node Version Manager curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash # Install required Node.js version nvm install # Install Yarn dependencies yarn install # Start the frontend yarn start Visit http://localhost:3000/","title":"Installation"},{"location":"sections/dev-guide/developer-guide/#backend","text":"","title":"Backend"},{"location":"sections/dev-guide/developer-guide/#dependencies_1","text":"Docker Docker Compose All backend packages are installed in the docker containers, however for faster auto-completion and intellisense, you can install them on the host machine: python -m venv venv source venv/bin/activate pip install -r requirements/local.txt","title":"Dependencies"},{"location":"sections/dev-guide/developer-guide/#helpful-commands","text":"","title":"Helpful Commands"},{"location":"sections/dev-guide/developer-guide/#run-the-docker-compose-stack-in-the-background","text":"docker compose up -d","title":"Run the docker compose stack in the background"},{"location":"sections/dev-guide/developer-guide/#watch-the-logs-of-django-the-backend-workers","text":"docker compose logs -f django celeryworker","title":"Watch the logs of Django &amp; the backend workers"},{"location":"sections/dev-guide/developer-guide/#watch-the-logs-of-all-services","text":"docker compose logs -f","title":"Watch the logs of all services:"},{"location":"sections/dev-guide/developer-guide/#create-a-super-user-account","text":"docker compose run --rm django python manage.py createsuperuser","title":"Create a super user account:"},{"location":"sections/dev-guide/developer-guide/#create-a-fresh-demo-project-with-synthetic-data","text":"docker compose run --rm django python manage.py create_demo_project","title":"Create a fresh demo project with synthetic data"},{"location":"sections/dev-guide/developer-guide/#run-tests","text":"docker compose run --rm django python manage.py test","title":"Run tests"},{"location":"sections/dev-guide/developer-guide/#run-tests-with-a-specific-pattern-in-the-test-name","text":"docker compose run --rm django python manage.py test -k pattern","title":"Run tests with a specific pattern in the test name"},{"location":"sections/dev-guide/developer-guide/#run-tests-and-drop-into-interactive-shell-on-failure","text":"docker compose run --rm django python manage.py test -k pattern --failfast --pdb","title":"Run tests and drop into interactive shell on failure"},{"location":"sections/dev-guide/developer-guide/#speed-up-development-of-tests-by-reusing-the-db-between-test-runs","text":"docker compose run --rm django python manage.py test --keepdb","title":"Speed up development of tests by reusing the db between test runs"},{"location":"sections/dev-guide/developer-guide/#run-management-scripts","text":"docker compose run django python manage.py --help","title":"Run management scripts"},{"location":"sections/dev-guide/developer-guide/#launch-the-django-shell","text":"docker compose exec django python manage.py shell >>> from ami.main.models import SourceImage, Occurrence >>> SourceImage.objects.all(project__name='myproject')","title":"Launch the Django shell:"},{"location":"sections/dev-guide/developer-guide/#install-backend-dependencies-locally-for-ide-support-intellisense-etc","text":"python -m venv venv source venv/bin/activate pip install -r requirements/local.txt","title":"Install backend dependencies locally for IDE support (Intellisense, etc):"},{"location":"sections/dev-guide/developer-guide/#generate-openapi-schema","text":"docker compose run --rm django python manage.py spectacular --api-version 'api' --format openapi --file ami-openapi-schema.yaml","title":"Generate OpenAPI schema"},{"location":"sections/dev-guide/developer-guide/#generate-typescript-types-from-openapi-schema","text":"docker run --rm -v ${PWD}:/local openapitools/openapi-generator-cli generate -i /local/ami-openapi-schema.yaml -g typescript-axios -o /local/ui/src/api-schema.d.ts","title":"Generate TypeScript types from OpenAPI schema"},{"location":"sections/dev-guide/developer-guide/#generate-diagram-graph-of-django-models-relationships-graphviz-required","text":"docker compose run --rm django python manage.py graph_models -a -o models.dot --dot dot -Tsvg models.dot > models.svg","title":"Generate diagram graph of Django models &amp; relationships (Graphviz required)"},{"location":"sections/dev-guide/developer-guide/#project-data-storage","text":"Each project manages its own external data storage where the AMI Platform will index and process images. This is most typically a public or private S3 bucket at a cloud provider that is not AWS. For example, the Swift object storage service at Compute Canada or a university's own storage service. To test the S3 storage backend locally, Minio is configured to run as part of the docker compose stack. To configure a project connect to the Minio service, you can use the following config: Endpoint URL: http://minio:9000 Access key: amistorage Secret access key: amistorage Public base URL: http://minio:9000/ami/ Bucket: ami Open the Minio web interface at http://localhost:9001 and login with the access key and secret access key. Upload some test images to a subfolder in the ami bucket (one subfolder per deployment) Give the bucket or folder anonymous access using the \"Anonymous access\" button in the Minio web interface. Both public and private buckets with presigned URLs should work. Add entries to your local /etc/hosts file to map the minio and django hostnames to localhost so the same image URLs can be viewed in your host machine's browser and processed in the backend containers. 127.0.0.1 minio 127.0.0.1 django","title":"Project Data Storage"},{"location":"sections/dev-guide/developer-guide/#email","text":"The local environment uses the console email backend. To view emails sent by the platform, check the console output (run the docker compose logs -f django celeryworker command).","title":"Email"},{"location":"sections/dev-guide/developer-guide/#database","text":"The local environment uses a local PostgreSQL database in a Docker container.","title":"Database"},{"location":"sections/dev-guide/developer-guide/#backup-and-restore","text":"docker compose run --rm postgres backup","title":"Backup and Restore"},{"location":"sections/dev-guide/developer-guide/#reset-the-database","text":"docker compose run --rm django python manage.py reset_db","title":"Reset the database"},{"location":"sections/dev-guide/developer-guide/#show-backups","text":"docker compose run --rm postgres backups","title":"Show backups"},{"location":"sections/dev-guide/developer-guide/#restore-a-backup","text":"docker compose run --rm postgres restore <backup_file_name>","title":"Restore a backup"},{"location":"sections/dev-guide/developer-guide/#load-fixtures-with-test-data","text":"docker compose run --rm django python manage.py migrate","title":"Load fixtures with test data"},{"location":"sections/dev-guide/update-documentation/","text":"Update documentation The documentation lives in the public GitHub repository antenna-docs . To suggest updates, you first need a GitHub account . Once logged in, you can start open pull requests to add or update articles. All contributions are much appreciated! Articles are written in Markdown format. There are currently 2 main categories of articles. The User Guide includes articles for Antenna users. The Developer Guide includes articles for Antenna contributors. Tip Do you need a quick reference to the Markdown syntax? Checkout this Markdown Cheat Sheet ! Add a new article Go to the folder user-guide or dev-guide Add a new file to the folder. Make sure it uses the Markdown extension, for example new-article.md . Write the article To make the new article show up in the sidebar, add a row to mkdocs.yml Open a pull request with the changes Update an existing article Go to the folder user-guide or dev-guide Locate the article and update it Open a pull request with the changes","title":"Update documentation"},{"location":"sections/dev-guide/update-documentation/#update-documentation","text":"The documentation lives in the public GitHub repository antenna-docs . To suggest updates, you first need a GitHub account . Once logged in, you can start open pull requests to add or update articles. All contributions are much appreciated! Articles are written in Markdown format. There are currently 2 main categories of articles. The User Guide includes articles for Antenna users. The Developer Guide includes articles for Antenna contributors. Tip Do you need a quick reference to the Markdown syntax? Checkout this Markdown Cheat Sheet !","title":"Update documentation"},{"location":"sections/dev-guide/update-documentation/#add-a-new-article","text":"Go to the folder user-guide or dev-guide Add a new file to the folder. Make sure it uses the Markdown extension, for example new-article.md . Write the article To make the new article show up in the sidebar, add a row to mkdocs.yml Open a pull request with the changes","title":"Add a new article"},{"location":"sections/dev-guide/update-documentation/#update-an-existing-article","text":"Go to the folder user-guide or dev-guide Locate the article and update it Open a pull request with the changes","title":"Update an existing article"},{"location":"sections/user-guide/account-creation/","text":"Account creation","title":"Account creation"},{"location":"sections/user-guide/account-creation/#account-creation","text":"","title":"Account creation"},{"location":"sections/user-guide/account-creation/#_1","text":"","title":""},{"location":"sections/user-guide/browsing-processed-data/","text":"Browsing processed data","title":"Browsing processed data"},{"location":"sections/user-guide/browsing-processed-data/#browsing-processed-data","text":"","title":"Browsing processed data"},{"location":"sections/user-guide/browsing-processed-data/#_1","text":"","title":""},{"location":"sections/user-guide/exporting-data/","text":"Exporting data","title":"Exporting data"},{"location":"sections/user-guide/exporting-data/#exporting-data","text":"","title":"Exporting data"},{"location":"sections/user-guide/exporting-data/#_1","text":"","title":""},{"location":"sections/user-guide/processing-data/","text":"Processing data Warning Batch processing is currently in development and problems are likely to occur. If you need data processed, we recommend to reach out to the team for support. Thank you for your patience! Demo","title":"Processing data"},{"location":"sections/user-guide/processing-data/#processing-data","text":"Warning Batch processing is currently in development and problems are likely to occur. If you need data processed, we recommend to reach out to the team for support. Thank you for your patience!","title":"Processing data"},{"location":"sections/user-guide/processing-data/#demo","text":"","title":"Demo"},{"location":"sections/user-guide/project-creation/","text":"Creating a project Demo","title":"Creating a project"},{"location":"sections/user-guide/project-creation/#creating-a-project","text":"","title":"Creating a project"},{"location":"sections/user-guide/project-creation/#demo","text":"","title":"Demo"},{"location":"sections/user-guide/reviewing-data/","text":"Reviewing imported data","title":"Reviewing imported data"},{"location":"sections/user-guide/reviewing-data/#reviewing-imported-data","text":"","title":"Reviewing imported data"},{"location":"sections/user-guide/reviewing-data/#_1","text":"","title":""},{"location":"sections/user-guide/uploading-data/","text":"Uploading data Configuring a data source Demo Image requirements Valid image formats are PNG, GIF and JPEG. Image filenames must contain a timestamp with year, month, day, hours, minutes and seconds (e.g. 20210101120000-snapshot.jpg). The timestamp in the filename makes it possible to do fast indexing of files, which is helpful when reading a large amount of images from a remote storage. Renaming images If images filenames are not matching the requirements, the images have to be renamed before being uploaded. To automate this process, we recommend this Python utility that renames image files based on their EXIF timestamp data. The script can recursively scan directories and renames files using the format prefix-YYYYMMDDHHmmSS.ext . Install the utility First, download and install Python . Then try this command to make sure the installation was successful. python --version Next, install the utility. pip install https://github.com/mihow/ami-camera-utils/archive/refs/heads/main.zip pip install --upgrade typer Then try this command to make sure the installation was successful. photo-renamer --help Use the utility To rename photos in a folder, use this command. Replace the dummy path with the directory containing images to rename. The script will show a confirmation prompt before proceeding. photo-renamer \"path/to/photos\" --inplace For more options, checkout the utility documention .","title":"Uploading data"},{"location":"sections/user-guide/uploading-data/#uploading-data","text":"","title":"Uploading data"},{"location":"sections/user-guide/uploading-data/#configuring-a-data-source","text":"","title":"Configuring a data source"},{"location":"sections/user-guide/uploading-data/#demo","text":"","title":"Demo"},{"location":"sections/user-guide/uploading-data/#image-requirements","text":"Valid image formats are PNG, GIF and JPEG. Image filenames must contain a timestamp with year, month, day, hours, minutes and seconds (e.g. 20210101120000-snapshot.jpg). The timestamp in the filename makes it possible to do fast indexing of files, which is helpful when reading a large amount of images from a remote storage.","title":"Image requirements"},{"location":"sections/user-guide/uploading-data/#renaming-images","text":"If images filenames are not matching the requirements, the images have to be renamed before being uploaded. To automate this process, we recommend this Python utility that renames image files based on their EXIF timestamp data. The script can recursively scan directories and renames files using the format prefix-YYYYMMDDHHmmSS.ext .","title":"Renaming images"},{"location":"sections/user-guide/uploading-data/#install-the-utility","text":"First, download and install Python . Then try this command to make sure the installation was successful. python --version Next, install the utility. pip install https://github.com/mihow/ami-camera-utils/archive/refs/heads/main.zip pip install --upgrade typer Then try this command to make sure the installation was successful. photo-renamer --help","title":"Install the utility"},{"location":"sections/user-guide/uploading-data/#use-the-utility","text":"To rename photos in a folder, use this command. Replace the dummy path with the directory containing images to rename. The script will show a confirmation prompt before proceeding. photo-renamer \"path/to/photos\" --inplace For more options, checkout the utility documention .","title":"Use the utility"},{"location":"sections/user-guide/validating-data/","text":"Validating data Demo","title":"Validating data"},{"location":"sections/user-guide/validating-data/#validating-data","text":"","title":"Validating data"},{"location":"sections/user-guide/validating-data/#demo","text":"","title":"Demo"},{"location":"sections/user-guide/visualizing-data/","text":"Visualizing data","title":"Visualizing data"},{"location":"sections/user-guide/visualizing-data/#visualizing-data","text":"","title":"Visualizing data"},{"location":"sections/user-guide/visualizing-data/#_1","text":"","title":""}]}